{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1177b42",
   "metadata": {},
   "source": [
    "1.prepare cluster set\n",
    "Use the WSI processing tool provided by [CONCHv1.5](https://github.com/mahmoodlab/CONCH) to extract pretrained feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "985b0b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: TCGA-3C-AALI-01.h5\n",
      "CONCH file: /data1/baizhiwang/Summary/Githubcode/WSISum/demo/CONCH/TCGA-3C-AALI-01.h5\n",
      "Sampled patches: 500 (target=500)\n",
      "[Done] Saved: /data1/baizhiwang/Summary/Githubcode/WSISum/demo/TCGA-3C-AALI-01_cluster.h5\n",
      "features: (501, 768) (last row = WSI PCA feature)\n",
      "coords:    (500, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "\n",
    "\n",
    "def load_pca_model(pca_model_path=\"/data/Summary/train_PCA/pca_model3.pkl\"):\n",
    "    \"\"\"Load saved PCA model.\"\"\"\n",
    "    with open(pca_model_path, \"rb\") as f:\n",
    "        pca = pickle.load(f)\n",
    "    return pca\n",
    "\n",
    "\n",
    "def apply_pca_to_single_sample(sample_features, pca):\n",
    "    \"\"\"Apply PCA to a single sample (1, dim) -> (1, 768).\"\"\"\n",
    "    return pca.transform(sample_features)\n",
    "\n",
    "\n",
    "def demo_single_h5(\n",
    "    dataset_dir,          # e.g. \"/data4/embedding/TCGA-BRCA\"\n",
    "    slide_file,           # e.g. \"TCGA-XX-XXXX.h5\"\n",
    "    out_h5_path,          # e.g. \"/data/Summary/demo_out/TCGA-XX-XXXX.h5\"\n",
    "    sample_size=500,\n",
    "    n_clusters=50,\n",
    "    pca_model_path=\"/data/Summary/train_PCA/pca_model3.pkl\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Simple demo:\n",
    "    - Read CONCH patch features/coords\n",
    "    - KMeans cluster\n",
    "    - Proportional sampling per cluster\n",
    "    - Read WSI features from TITAN/CHIEF/PRISM\n",
    "    - PCA reduce to 768\n",
    "    - Append WSI to patch features and save\n",
    "    \"\"\"\n",
    "\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)\n",
    "\n",
    "    pca = load_pca_model(pca_model_path)\n",
    "\n",
    "    # paths\n",
    "    conch_h5_path = os.path.join(dataset_dir, \"CONCH\", slide_file)\n",
    "    if not os.path.exists(conch_h5_path):\n",
    "        print(f\"[Skip] Missing CONCH file: {conch_h5_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nProcessing: {slide_file}\")\n",
    "    print(f\"CONCH file: {conch_h5_path}\")\n",
    "\n",
    "    # load CONCH features + coords\n",
    "    with h5py.File(conch_h5_path, \"r\") as f:\n",
    "        conch_features = f[\"features\"][:]  # (n, 768)\n",
    "        conch_coords = f[\"coords\"][:]      # (n, 2)\n",
    "\n",
    "    n = conch_features.shape[0]\n",
    "    if n == 0:\n",
    "        print(\"[Skip] CONCH features = 0\")\n",
    "        return\n",
    "\n",
    "    # if n < n_clusters, repeat to n_clusters\n",
    "    if n < n_clusters:\n",
    "        times = (n_clusters + n - 1) // n\n",
    "        conch_features = np.tile(conch_features, (times, 1))[:n_clusters]\n",
    "        conch_coords = np.tile(conch_coords, (times, 1))[:n_clusters]\n",
    "        n = n_clusters\n",
    "        print(f\"[Repeat] Expanded to {n} for clustering\")\n",
    "\n",
    "    # KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=\"auto\")\n",
    "    labels = kmeans.fit_predict(conch_features)\n",
    "\n",
    "    cluster_indices = {}\n",
    "    for i, lab in enumerate(labels):\n",
    "        cluster_indices.setdefault(lab, []).append(i)\n",
    "\n",
    "    # if n < sample_size, repeat to sample_size\n",
    "    if n < sample_size:\n",
    "        times = (sample_size + n - 1) // n\n",
    "        conch_features = np.tile(conch_features, (times, 1))[:sample_size]\n",
    "        conch_coords = np.tile(conch_coords, (times, 1))[:sample_size]\n",
    "        n = sample_size\n",
    "        print(f\"[Repeat] Expanded to {n} for sampling\")\n",
    "\n",
    "    # proportional allocation\n",
    "    cluster_sizes = {cid: len(idxs) for cid, idxs in cluster_indices.items()}\n",
    "\n",
    "    cluster_select = {}\n",
    "    sum_alloc = 0\n",
    "    for cid, size in cluster_sizes.items():\n",
    "        fraction = size / n\n",
    "        cnt = int(round(sample_size * fraction))\n",
    "        cluster_select[cid] = cnt\n",
    "        sum_alloc += cnt\n",
    "\n",
    "    # adjust rounding\n",
    "    diff = sample_size - sum_alloc\n",
    "    cids = list(cluster_select.keys())\n",
    "\n",
    "    while diff != 0:\n",
    "        if diff > 0:\n",
    "            cid = random.choice(cids)\n",
    "            cluster_select[cid] += 1\n",
    "            diff -= 1\n",
    "        else:\n",
    "            candidates = [c for c in cids if cluster_select[c] > 0]\n",
    "            if not candidates:\n",
    "                break\n",
    "            cid = random.choice(candidates)\n",
    "            cluster_select[cid] -= 1\n",
    "            diff += 1\n",
    "\n",
    "    # sample each cluster\n",
    "    selected_indices = []\n",
    "    for cid, need in cluster_select.items():\n",
    "        all_idxs = cluster_indices[cid]\n",
    "        if need >= len(all_idxs):\n",
    "            selected_indices.extend(all_idxs)\n",
    "        else:\n",
    "            selected_indices.extend(random.sample(all_idxs, need))\n",
    "\n",
    "    selected_indices = sorted(selected_indices)\n",
    "\n",
    "    sampled_features = conch_features[selected_indices]\n",
    "    sampled_coords = conch_coords[selected_indices]\n",
    "\n",
    "    print(f\"Sampled patches: {sampled_features.shape[0]} (target={sample_size})\")\n",
    "\n",
    "    # read WSI features from multiple models\n",
    "    models = [\"TITAN\", \"CHIEF\", \"PRISM\"]\n",
    "    multi_features = []\n",
    "\n",
    "    for model in models:\n",
    "        model_h5 = os.path.join(dataset_dir, model, slide_file)\n",
    "        if os.path.exists(model_h5):\n",
    "            with h5py.File(model_h5, \"r\") as f:\n",
    "                feat = f[\"features\"][:]  # expected (1, dim)\n",
    "            multi_features.append(feat)\n",
    "        else:\n",
    "            print(f\"[Warning] Missing model file: {model_h5}\")\n",
    "\n",
    "    if len(multi_features) == 0:\n",
    "        print(\"[Skip] No model features found. Nothing to PCA.\")\n",
    "        return\n",
    "\n",
    "    # concatenate WSI features -> PCA\n",
    "    all_wsi_feat = np.concatenate(multi_features, axis=-1).reshape(1, -1)\n",
    "    wsi_feature_768 = apply_pca_to_single_sample(all_wsi_feat, pca)\n",
    "\n",
    "    # append WSI row\n",
    "    combined_features = np.concatenate([sampled_features, wsi_feature_768], axis=0)\n",
    "\n",
    "    # save\n",
    "    os.makedirs(os.path.dirname(out_h5_path), exist_ok=True)\n",
    "    with h5py.File(out_h5_path, \"w\") as fout:\n",
    "        fout.create_dataset(\"features\", data=combined_features)\n",
    "        fout.create_dataset(\"coords\", data=sampled_coords)\n",
    "\n",
    "    print(f\"[Done] Saved: {out_h5_path}\")\n",
    "    print(f\"features: {combined_features.shape} (last row = WSI PCA feature)\")\n",
    "    print(f\"coords:    {sampled_coords.shape}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Example usage (Jupyter cell)\n",
    "# -----------------------------\n",
    "dataset_dir = \"/data1/baizhiwang/Summary/Githubcode/WSISum/demo\"\n",
    "slide_file = \"TCGA-3C-AALI-01.h5\"\n",
    "\n",
    "out_h5_path = \"/data1/baizhiwang/Summary/Githubcode/WSISum/demo/TCGA-3C-AALI-01_cluster.h5\"\n",
    "\n",
    "demo_single_h5(\n",
    "    dataset_dir=dataset_dir,\n",
    "    slide_file=slide_file,\n",
    "    out_h5_path=out_h5_path,\n",
    "    sample_size=500,\n",
    "    n_clusters=50,\n",
    "    pca_model_path=\"/data1/baizhiwang/Summary/Githubcode/WSISum/demo/pca_model3.pkl\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a10a54",
   "metadata": {},
   "source": [
    "2.run WSI summarization\n",
    "    we provide pretrained model you can download from  https://pan.baidu.com/s/1EJtMzgES_RBJ_49wYl6C2Q?pwd=phjv \n",
    "    and put the checkpoint in demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "733f2ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4123669/2725311064.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_pth, map_location=\"cuda\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Done!\n",
      "Input:  /data1/baizhiwang/Summary/Githubcode/WSISum/demo/TCGA-3C-AALI-01_cluster.h5\n",
      "Output: /data1/baizhiwang/Summary/Githubcode/WSISum/demo/TCGA-3C-AALI-01_summary.h5\n",
      "Summary shape: torch.Size([63, 768])\n",
      "Best cosine similarity: 0.9741\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import sys\n",
    "sys.path.append(\"/data1/baizhiwang/Summary/Githubcode/WSISum\")\n",
    "import utils\n",
    "import modeling_pretrain\n",
    "import random\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from timm.models import create_model\n",
    "\n",
    "from datasets import DataAugmentationForMAE\n",
    "\n",
    "\n",
    "def run_mae_summary(\n",
    "    input_h5: str,\n",
    "    model_pth: str,\n",
    "    out_h5: str,\n",
    "    device: str = \"cuda:0\",\n",
    "    model_name: str = \"pretrain_mae_base_patch16_224\",\n",
    "    mask_ratio: float = 0.875,\n",
    "    drop_path: float = 0.0,\n",
    "    max_iterations: int = 1000,\n",
    "    min_iterations: int = 1000,\n",
    "    threshold: float = 0.98,\n",
    "):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        input_h5: .h5 file with dataset \"features\" shape (N+1, 768)\n",
    "                  last row is WSI feature\n",
    "        model_pth: MAE checkpoint path (.pth)\n",
    "    Output:\n",
    "        out_h5: .h5 file with dataset \"features\" = best_summary (num_tokens, 768)\n",
    "    \"\"\"\n",
    "\n",
    "    # reproducibility (optional)\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    dev = torch.device(device)\n",
    "\n",
    "    # ---- load model ----\n",
    "    model = create_model(\n",
    "        model_name,\n",
    "        pretrained=False,\n",
    "        drop_path_rate=drop_path,\n",
    "        drop_block_rate=None,\n",
    "    )\n",
    "    checkpoint = torch.load(model_pth, map_location=\"cuda\")\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    model.to(dev)\n",
    "    model.eval()\n",
    "\n",
    "    # ---- read input h5 ----\n",
    "    with h5py.File(input_h5, \"r\") as f:\n",
    "        feats = f[\"features\"][:].copy()   # (N+1, 768)\n",
    "\n",
    "    # ---- build minimal args object for DataAugmentationForMAE ----\n",
    "    class Args:\n",
    "        pass\n",
    "\n",
    "    args = Args()\n",
    "    args.mask_ratio = mask_ratio\n",
    "    args.input_size = 224\n",
    "    args.imagenet_default_mean_and_std = True\n",
    "    args.window_size = 64\n",
    "    args.patch_size = 64\n",
    "\n",
    "    transforms = DataAugmentationForMAE(args)\n",
    "\n",
    "    # ---- apply transform (produces tokens + mask) ----\n",
    "    img1, bool_masked_pos = transforms(feats)\n",
    "\n",
    "    # last token is WSI embedding\n",
    "    WSIfeature = img1[:, -1, :].to(dev)       # (1, 768)\n",
    "\n",
    "    # patch tokens\n",
    "    img = img1[:, :-1, :]                      # (1, N, 768)\n",
    "\n",
    "    bool_masked_pos = torch.from_numpy(bool_masked_pos)  # (N+1,)\n",
    "\n",
    "    # initial summary tokens = unmasked patch tokens (ignore WSI token mask index 0)\n",
    "    summary = img[:, ~bool_masked_pos[1:].bool(), :].squeeze(0)  # (K, 768)\n",
    "\n",
    "    best_summary = summary\n",
    "    max_cosine_similarity = -1.0\n",
    "\n",
    "    # ---- iteration loop ----\n",
    "    for i in range(max_iterations):\n",
    "        with torch.no_grad():\n",
    "            bool_masked_pos_batch = bool_masked_pos[None, :].to(dev).flatten(1).to(torch.bool)\n",
    "            img_batch = img.to(dev)\n",
    "\n",
    "            outputs, cls = model(img_batch, bool_masked_pos_batch)  # cls: (1, 768)\n",
    "\n",
    "            # cosine similarity between cls and WSIfeature\n",
    "            dot = torch.sum(cls * WSIfeature, dim=1)\n",
    "            cos = dot / (torch.norm(cls, dim=1) * torch.norm(WSIfeature, dim=1))\n",
    "\n",
    "            if cos > max_cosine_similarity:\n",
    "                max_cosine_similarity = cos\n",
    "                best_summary = summary\n",
    "\n",
    "            if i >= (min_iterations - 1) and max_cosine_similarity.item() >= threshold:\n",
    "                print(f\"Early stop at iter {i+1}, sim={max_cosine_similarity.item():.4f}\")\n",
    "                break\n",
    "\n",
    "    # ---- save output ----\n",
    "    os.makedirs(os.path.dirname(out_h5), exist_ok=True)\n",
    "    with h5py.File(out_h5, \"w\") as fout:\n",
    "        fout.create_dataset(\"features\", data=best_summary.cpu().numpy())\n",
    "\n",
    "    print(f\"\\n✅ Done!\")\n",
    "    print(f\"Input:  {input_h5}\")\n",
    "    print(f\"Output: {out_h5}\")\n",
    "    print(f\"Summary shape: {best_summary.shape}\")\n",
    "    print(f\"Best cosine similarity: {max_cosine_similarity.item():.4f}\")\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Example usage (Notebook)\n",
    "# -----------------------\n",
    "input_h5 = \"/data1/baizhiwang/Summary/Githubcode/WSISum/demo/TCGA-3C-AALI-01_cluster.h5\"\n",
    "model_pth = \"/data1/baizhiwang/Summary/Githubcode/WSISum/demo/MOE-500-3model.pth\"\n",
    "out_h5 = \"/data1/baizhiwang/Summary/Githubcode/WSISum/demo/TCGA-3C-AALI-01_summary.h5\"\n",
    "\n",
    "run_mae_summary(input_h5, model_pth, out_h5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5775520",
   "metadata": {},
   "source": [
    "Then this WSIsummarization can be used to downstream tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
